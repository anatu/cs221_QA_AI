{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from functools import reduce\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import os as os\n",
    "import json\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers, callbacks, models\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from datetime import datetime\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 100, 100, 100\n"
     ]
    }
   ],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 100\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "MODEL_NAME = \"LSTM_SelfAttention\"\n",
    "# Regularization parameter\n",
    "LAMBDA = 0.02\n",
    "print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n",
    "                                                           EMBED_HIDDEN_SIZE,\n",
    "                                                           SENT_HIDDEN_SIZE,\n",
    "                                                           QUERY_HIDDEN_SIZE))\n",
    "\n",
    "path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = []\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa3_three-supporting-facts_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa4_two-arg-relations_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa5_three-arg-relations_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa6_yes-no-questions_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa7_counting_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa8_lists-sets_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa9_simple-negation_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa10_indefinite-knowledge_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa11_basic-coreference_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa12_conjunction-fact_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa13_compound-coreference_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa14_time-reasoning_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa15_basic-deduction_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa16_basic-induction_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa17_positional-reasoning_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa18_size-reasoning_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa19_path-finding_{}.txt')\n",
    "challenge.append('tasks_1-20_v1-2/en-10k/qa20_agents-motivations_{}.txt')\n",
    "\n",
    "\n",
    "def extract_stories(text):\n",
    "    story_out = []\n",
    "    new_story = []\n",
    "    for line in text.readlines():\n",
    "        line = line.decode('utf-8').strip()\n",
    "        number, line = line.split(' ', 1)\n",
    "        if int(number) == 1: \n",
    "            new_story = []\n",
    "        if '\\t' in line:\n",
    "            question, answer, _ = line.split('\\t')\n",
    "            question = re.findall(r\"[\\w']+|[.,!?]\", question)\n",
    "            passage = []\n",
    "            for i,j in enumerate(new_story):\n",
    "                if j:\n",
    "                    passage.append([str(i)+\":\"]+j)\n",
    "            story_out.append((passage, question, answer))\n",
    "        else: \n",
    "            new_story.append(re.findall(r\"[\\w']+|[.,!?]\", line))\n",
    "    return story_out\n",
    "    \n",
    "with tarfile.open(path) as tar:\n",
    "    train_stories = extract_stories(tar.extractfile(challenge[0].format('train')))\n",
    "    test_stories = extract_stories(tar.extractfile(challenge[0].format('test')))\n",
    "np.random.shuffle(train_stories)\n",
    "np.random.shuffle(test_stories)\n",
    "\n",
    "stories = train_stories + test_stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "8\n",
      "10\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "story_maxlen = max((len(s) for x, _, _ in stories for s in x))\n",
    "story_maxsents = max((len(x) for x, _, _ in stories))\n",
    "query_maxlen = max(len(x) for _, x, _ in stories)\n",
    "\n",
    "\n",
    "def flatten(text):\n",
    "    for i in text:\n",
    "        if (isinstance(i, collections.Iterable) and not isinstance(i,(str, bytes))): \n",
    "            yield from flatten(i)\n",
    "        else: \n",
    "            yield i\n",
    "\n",
    "vocab = sorted(set(flatten(stories)))\n",
    "vocab.insert(0, '<PAD>')\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "print(story_maxlen)\n",
    "print(story_maxsents)\n",
    "print(query_maxlen)\n",
    "\n",
    "word_idx = dict((c, i) for i, c in enumerate(vocab))\n",
    "\n",
    "def sort_corpus(data, word_idx):\n",
    "    passage_vect = []\n",
    "    question_vect = []\n",
    "    answer_vect = []\n",
    "    for corpus in data:\n",
    "        passage = corpus[0]\n",
    "        question = corpus[1]\n",
    "        answer = corpus[2]\n",
    "        passage_num = []\n",
    "        for lines in passage:\n",
    "            passage_num.append([word_idx[words] for words in lines])\n",
    "        passage_vect.append(passage_num)\n",
    "        question_vect.append([word_idx[words] for words in question]) \n",
    "        answer_vect.append([word_idx[answer]])\n",
    "        \n",
    "    return(passage_vect, question_vect, answer_vect)\n",
    "\n",
    "\n",
    "passage, question, answer = sort_corpus(train_stories, \n",
    "     word_idx)\n",
    "\n",
    "#padding train\n",
    "inputs_train = []\n",
    "for i in passage:\n",
    "    inputs_train.append(pad_sequences(i,maxlen=story_maxlen))\n",
    "queries_train = pad_sequences(question, maxlen=query_maxlen)\n",
    "answers_train = np.array(answer)\n",
    "\n",
    "\n",
    "passage, question, answer = sort_corpus(test_stories, \n",
    "     word_idx)\n",
    "\n",
    "#padding test\n",
    "inputs_test = []\n",
    "for i in passage:\n",
    "    inputs_test.append(pad_sequences(i,maxlen=story_maxlen))\n",
    "queries_test = pad_sequences(question, maxlen=query_maxlen)\n",
    "answers_test = np.array(answer)\n",
    "\n",
    "\n",
    "inputs_stack = []\n",
    "for i,j in enumerate(inputs_train):\n",
    "    inputs_stack.append(np.concatenate([j,np.zeros((story_maxsents-j.shape[0],story_maxlen),'int')]))\n",
    "inputs_train = np.stack(inputs_stack)\n",
    "\n",
    "inputs_stack = []\n",
    "for i,j in enumerate(inputs_test):\n",
    "    inputs_stack.append(np.concatenate([j,np.zeros((story_maxsents-j.shape[0],story_maxlen),'int')]))\n",
    "inputs_test = np.stack(inputs_stack)\n",
    "\n",
    "inps = [inputs_train, queries_train]\n",
    "val_inps = [inputs_test, queries_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py36/lib/python3.6/site-packages/ipykernel_launcher.py:39: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 9s 921us/step - loss: 1.3706 - acc: 0.4755 - val_loss: 0.3109 - val_acc: 0.9560\n",
      "Epoch 2/100\n",
      " 2880/10000 [=======>......................] - ETA: 4s - loss: 0.3575 - acc: 0.9382"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-910a2d677c5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m hist=answer.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n\u001b[0;32m---> 39\u001b[0;31m            validation_data=(val_inps, answers_test))\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emb_dim = 40\n",
    "def emb_sent_bow(inp):\n",
    "    emb_op = layers.TimeDistributed(Embedding(vocab_size, emb_dim, embeddings_regularizer=regularizers.l2(0.002)))\n",
    "    emb = emb_op(inp)\n",
    "    emb = layers.Dropout(0.1)(emb)\n",
    "    emb = layers.Lambda(lambda x: K.sum(x, 2))(emb)\n",
    "#     return Elemwise(0, False)(emb), emb_op\n",
    "    return emb, emb_op\n",
    "inp_story = layers.Input((story_maxsents, story_maxlen))\n",
    "inp_q = layers.Input((query_maxlen,))\n",
    "emb_story, emb_story_op = emb_sent_bow(inp_story)\n",
    "emb_q = emb_story_op.layer(inp_q)\n",
    "emb_q = layers.Lambda(lambda x: K.sum(x, 1))(emb_q)\n",
    "h = layers.Dense(emb_dim, kernel_regularizer=regularizers.l2(0.0000))\n",
    "def one_hop(u, A):\n",
    "    C, _ = emb_sent_bow(inp_story)\n",
    "    x = layers.Reshape((1, emb_dim))(u)\n",
    "    x = layers.Dot(axes=2)([A, x])\n",
    "    x = layers.Reshape((story_maxsents,))(x)\n",
    "    x = layers.Activation('softmax')(x)\n",
    "    match = layers.Reshape((story_maxsents,1))(x)\n",
    "\n",
    "    x = layers.Dot(axes=1)([match, C])\n",
    "    x = layers.Reshape((emb_dim,))(x)\n",
    "    x = h(x)\n",
    "    #x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Add()([x, emb_q])\n",
    "    return x, C\n",
    "response, emb_story = one_hop(emb_q, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)\n",
    "res = layers.Dense(vocab_size, activation='softmax')(response)\n",
    "answer = Model([inp_story, inp_q], res)\n",
    "answer.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "K.set_value(answer.optimizer.lr, 5e-3)\n",
    "hist=answer.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n",
    "           validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
