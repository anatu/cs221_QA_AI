{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from functools import reduce\n",
    "import re\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import os as os\n",
    "import json\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers, callbacks, models\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from datetime import datetime\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "\n",
    "from keras import regularizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(sent):\n",
    "    '''Return the tokens of a sentence including punctuation.\n",
    "    >>> tokenize('Bob dropped the apple. Where is the apple?')\n",
    "    ['Bob', 'dropped', 'the', 'apple', '.', 'Where', 'is', 'the', 'apple', '?']\n",
    "    '''\n",
    "    return [x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]\n",
    "\n",
    "\n",
    "def parse_stories(lines):\n",
    "    data = []\n",
    "    story = []\n",
    "    for line in lines:\n",
    "        line = line.decode('utf-8').strip()\n",
    "        nid, line = line.split(' ', 1)\n",
    "        if int(nid) == 1: story = []\n",
    "        if '\\t' in line:\n",
    "            q, a, supporting = line.split('\\t')\n",
    "            q = tokenize(q)\n",
    "            substory = None\n",
    "            substory = [[str(i)+\":\"]+x for i,x in enumerate(story) if x]\n",
    "            data.append((substory, q, a))\n",
    "            story.append('')\n",
    "        else: story.append(tokenize(line))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_stories(f):\n",
    "    data = parse_stories(f.readlines())\n",
    "    return [(story, q, answer) for story, q, answer in data]\n",
    "\n",
    "\n",
    "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
    "    X = []; Xq = []; Y = []\n",
    "    for story, query, answer in data:\n",
    "        x = [[word_idx[w] for w in s] for s in story]\n",
    "        xq = [word_idx[w] for w in query]\n",
    "        y = [word_idx[answer]]\n",
    "        X.append(x); Xq.append(xq); Y.append(y)\n",
    "    return ([pad_sequences(x, maxlen=story_maxlen) for x in X],\n",
    "            pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))\n",
    "\n",
    "def do_flatten(el): \n",
    "    return isinstance(el, collections.Iterable) and not isinstance(el, (str, bytes))\n",
    "def flatten(l):\n",
    "    for el in l:\n",
    "        if do_flatten(el): yield from flatten(el)\n",
    "        else: yield el\n",
    "            \n",
    "def stack_inputs(inputs):\n",
    "    for i,it in enumerate(inputs):\n",
    "        inputs[i] = np.concatenate([it, \n",
    "                           np.zeros((story_maxsents-it.shape[0],story_maxlen), 'int')])\n",
    "    return np.stack(inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 100, 100, 100\n"
     ]
    }
   ],
   "source": [
    "RNN = recurrent.LSTM\n",
    "EMBED_HIDDEN_SIZE = 100\n",
    "SENT_HIDDEN_SIZE = 100\n",
    "QUERY_HIDDEN_SIZE = 100\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 40\n",
    "MODEL_NAME = \"LSTM_SelfAttention\"\n",
    "# Regularization parameter\n",
    "LAMBDA = 0.02\n",
    "print('RNN / Embed / Sent / Query = {}, {}, {}, {}'.format(RNN,\n",
    "                                                           EMBED_HIDDEN_SIZE,\n",
    "                                                           SENT_HIDDEN_SIZE,\n",
    "                                                           QUERY_HIDDEN_SIZE))\n",
    "\n",
    "try:\n",
    "    path = get_file('babi-tasks-v1-2.tar.gz',\n",
    "                    origin='https://s3.amazonaws.com/text-datasets/'\n",
    "                           'babi_tasks_1-20_v1-2.tar.gz')\n",
    "except:\n",
    "    print('Error downloading dataset, please download it manually:\\n'\n",
    "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2'\n",
    "          '.tar.gz\\n'\n",
    "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
    "    raise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlandy\\Anaconda3\\lib\\re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "8\n",
      "88\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Default QA1 with 1000 samples\n",
    "#challenge = 'tasks_1-20_v1-2/en/qa1_single-supporting-fact_{}.txt'\n",
    "# QA1 with 10,000 samples\n",
    "# challenge = 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt'\n",
    "# QA2 with 1000 samples\n",
    "#challenge = 'tasks_1-20_v1-2/en/qa2_two-supporting-facts_{}.txt'\n",
    "# QA2 with 10,000 samples\n",
    "challenge = 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt'\n",
    "with tarfile.open(path) as tar:\n",
    "    train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
    "    test_stories = get_stories(tar.extractfile(challenge.format('test')))\n",
    "np.random.shuffle(train_stories)\n",
    "np.random.shuffle(test_stories)\n",
    "\n",
    "stories = train_stories + test_stories\n",
    "\n",
    "story_maxlen = max((len(s) for x, _, _ in stories for s in x))\n",
    "story_maxsents = max((len(x) for x, _, _ in stories))\n",
    "query_maxlen = max(len(x) for _, x, _ in stories)\n",
    "\n",
    "vocab = sorted(set(flatten(stories)))\n",
    "vocab.insert(0, '<PAD>')\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)\n",
    "print(story_maxlen)\n",
    "print(story_maxsents)\n",
    "print(query_maxlen)\n",
    "\n",
    "word_idx = dict((c, i) for i, c in enumerate(vocab))\n",
    "\n",
    "inputs_train, queries_train, answers_train = vectorize_stories(train_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)\n",
    "inputs_test, queries_test, answers_test = vectorize_stories(test_stories, \n",
    "     word_idx, story_maxlen, query_maxlen)\n",
    "\n",
    "inputs_train = stack_inputs(inputs_train)\n",
    "inputs_test = stack_inputs(inputs_test)\n",
    "\n",
    "inps = [inputs_train, queries_train]\n",
    "val_inps = [inputs_test, queries_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the embedding matrix...\n",
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "print(\"Building the embedding matrix...\")\n",
    "GLOVE_PATH = '..\\\\Embeddings'\n",
    "\n",
    "\n",
    "f = open(os.path.join(GLOVE_PATH,\"glove.6B.{}d.txt\".format(EMBED_HIDDEN_SIZE)), 'r', encoding = \"ANSI\")\n",
    "embeddings_index = {}\n",
    "for line in f:\n",
    "    values = line.split(\" \")\n",
    "    word = values[0]\n",
    "    try:\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "    except ValueError:\n",
    "        print(values[1:])\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_idx), EMBED_HIDDEN_SIZE))\n",
    "for word, i in word_idx.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "story_Input (InputLayer)        (None, 88, 8)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_66 (Embedding)        (None, 88, 8, 50)    6200        story_Input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "question_Input (InputLayer)     (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_71 (Reshape)            (None, 704, 50)      0           embedding_66[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "embedding_65 (Embedding)        (None, 5, 50)        6200        question_Input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_45 (Bidirectional (None, 704, 100)     40400       reshape_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_44 (Bidirectional (None, 5, 100)       40400       embedding_65[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_72 (Reshape)            (None, 704, 100)     0           bidirectional_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape_70 (Reshape)            (None, 5, 100)       0           bidirectional_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dot_26 (Dot)                    (None, 704, 5)       0           reshape_72[0][0]                 \n",
      "                                                                 reshape_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 704, 5)       0           dot_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_73 (Reshape)            (None, 704, 5)       0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dot_27 (Dot)                    (None, 704, 100)     0           reshape_73[0][0]                 \n",
      "                                                                 reshape_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 704, 200)     0           reshape_72[0][0]                 \n",
      "                                                                 dot_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 140800)       0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 50)           7040050     flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 124)          6324        dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 7,139,574\n",
      "Trainable params: 7,139,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "(1000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:66: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 76s 76ms/step - loss: 13.4935 - acc: 0.1870 - val_loss: 13.5003 - val_acc: 0.1650\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 13.7707 - acc: 0.1470 - val_loss: 13.4717 - val_acc: 0.1650\n",
      "Epoch 3/100\n",
      " 608/1000 [=================>............] - ETA: 22s - loss: 13.9335 - acc: 0.1365"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-8a9be7da5f66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswers_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m hist=model.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n\u001b[1;32m---> 66\u001b[1;33m            validation_data=(val_inps, answers_test))\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "emb_dim = EMBED_HIDDEN_SIZE\n",
    "\n",
    "question_Input = layers.Input(shape=(query_maxlen,), name='question_Input')\n",
    "story_Input = layers.Input(shape=(story_maxsents, story_maxlen), name='story_Input')\n",
    "\n",
    "#Embed question\n",
    "q_Embedding = layers.Embedding(input_dim = vocab_size, output_dim = emb_dim, \\\n",
    "                                weights = [embedding_matrix], input_length = query_maxlen)(question_Input)\n",
    "# Bidirectional GRU (optimal dropout approx 0.4 without regularization)\n",
    "q_Encode = layers.Bidirectional(recurrent.LSTM(emb_dim, return_sequences=True,\\\n",
    "                                              kernel_regularizer = regularizers.l2(LAMBDA), dropout=0.3))(q_Embedding)\n",
    "q_Encode = layers.Reshape((query_maxlen, 2*emb_dim))(q_Encode)\n",
    "\n",
    "#Embed story\n",
    "s_Embedding = layers.Embedding(input_dim = vocab_size, output_dim = emb_dim, \\\n",
    "                               weights = [embedding_matrix], input_length = (story_maxsents, story_maxlen))(story_Input)\n",
    "s_Embedding = layers.Reshape((story_maxlen * story_maxsents, emb_dim))(s_Embedding)\n",
    "# Bidirectional GRU (optimal dropout approx 0.4 without regularization)\n",
    "s_Encode = layers.Bidirectional(recurrent.LSTM(emb_dim, return_sequences=True, \\\n",
    "                                              kernel_regularizer = regularizers.l2(LAMBDA), dropout=0.3))(s_Embedding)\n",
    "s_Encode = layers.Reshape((story_maxlen*story_maxsents, 2*emb_dim))(s_Encode)\n",
    "\n",
    "# Attention Layer\n",
    "# Multiply between context and query to form attention\n",
    "# Resultant matrix should be MxN, taking in Mxd and Nxd \n",
    "# embedded question/answer matrices where d is 2*EMBED_HIDDEN_SIZE\n",
    "dot_merge = layers.Dot(axes = [2,2])([s_Encode, q_Encode])\n",
    "\n",
    "# Flatten and compute softmax for each attent distro\n",
    "flat = Flatten()(dot_merge)\n",
    "dense = layers.Dense(query_maxlen * story_maxlen, kernel_regularizer = regularizers.l2(LAMBDA))(flat)\n",
    "# act = layers.Activation(\"softmax\")(dense)\n",
    "act = layers.Activation(\"softmax\")(dot_merge)\n",
    "\n",
    "\n",
    "# Reshape back into the original dimensions (MxN)\n",
    "act_resh = layers.Reshape((story_maxlen*story_maxsents, query_maxlen), input_shape=(query_maxlen,))(act)\n",
    "# Compute attention output as an element-wise multiplication\n",
    "attn_out = layers.Dot(axes=[2,1])([act_resh, q_Encode])\n",
    "# Next we concatenate to form a blended representation of the same dimension as an encoded question,\n",
    "# of which there exists one for every given context hidden state. Should be 4H x 2N\n",
    "blended = layers.Concatenate(axis=2)([s_Encode, attn_out])\n",
    "flat2 = Flatten()(blended)\n",
    "#relu = layers.Activation(\"relu\")(flat2)\n",
    "\n",
    "#####\n",
    "# TODO: Finish Logit + fully connected layer for RELU \n",
    "relu = layers.Dense(emb_dim, activation = \"relu\")(flat2)\n",
    "#logit = layers.Dense(1)(relu)\n",
    "#####\n",
    "#print(relu.get_shape(), logit.get_shape())\n",
    "\n",
    "\n",
    "dense2 = layers.Dense(vocab_size, activation = \"softmax\", kernel_regularizer = regularizers.l2(LAMBDA))(relu)\n",
    "######\n",
    "# TODO: Add vanilla softmax at output (no weight vector here, i.e. no Dense) \n",
    "# dense2 = layers.Activation(\"softmax\")(logit)\n",
    "#####\n",
    "\n",
    "model = Model(inputs=[story_Input, question_Input], outputs = dense2)\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "K.set_value(model.optimizer.lr, 1e-2)\n",
    "print(answers_train.shape)\n",
    "hist=model.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n",
    "           validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 5)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 88, 8)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_56 (Embedding)        (None, 5, 20)        2480        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_8 (TimeDistrib (None, 88, 8, 20)    2480        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 20)           0           embedding_56[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 88, 20)       0           time_distributed_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "reshape_54 (Reshape)            (None, 1, 20)        0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_18 (Dot)                    (None, 88, 1)        0           lambda_7[0][0]                   \n",
      "                                                                 reshape_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_55 (Reshape)            (None, 88)           0           dot_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 88)           0           reshape_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_9 (TimeDistrib (None, 88, 8, 20)    2480        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_56 (Reshape)            (None, 88, 1)        0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 88, 20)       0           time_distributed_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dot_19 (Dot)                    (None, 1, 20)        0           reshape_56[0][0]                 \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_57 (Reshape)            (None, 20)           0           dot_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 124)          2604        reshape_57[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 10,044\n",
      "Trainable params: 10,044\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      " 9280/10000 [==========================>...] - ETA: 0s - loss: 1.7591 - acc: 0.2546"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-9705077888da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1e-2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m hist=model.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n\u001b[1;32m---> 31\u001b[1;33m            validation_data=(val_inps, answers_test))\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "\n",
    "emb_dim = 20\n",
    "def emb_sent_bow(inp):\n",
    "    emb = layers.TimeDistributed(Embedding(vocab_size, emb_dim))(inp)\n",
    "    return layers.Lambda(lambda x: K.sum(x, 2))(emb)\n",
    "inp_story = layers.Input((story_maxsents, story_maxlen))\n",
    "emb_story = emb_sent_bow(inp_story)\n",
    "inp_story.shape, emb_story.shape\n",
    "inp_q = layers.Input((query_maxlen,))\n",
    "emb_q = layers.Embedding(vocab_size, emb_dim)(inp_q)\n",
    "emb_q = layers.Lambda(lambda x: K.sum(x, 1))(emb_q)\n",
    "emb_q = layers.Reshape((1, emb_dim))(emb_q)\n",
    "inp_q.shape, emb_q.shape\n",
    "x = layers.Dot(axes=2)([emb_story, emb_q])\n",
    "x = layers.Reshape((story_maxsents,))(x)\n",
    "x = layers.Activation('softmax')(x)\n",
    "match = layers.Reshape((story_maxsents,1))(x)\n",
    "match.shape\n",
    "emb_c = emb_sent_bow(inp_story)\n",
    "x = layers.Dot(axes=1)([match, emb_c])\n",
    "response = layers.Reshape((emb_dim,))(x)\n",
    "res = layers.Dense(vocab_size, activation='softmax')(response)\n",
    "model = Model([inp_story, inp_q], res)\n",
    "print(model.summary())\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "K.set_value(model.optimizer.lr, 1e-2)\n",
    "hist=model.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n",
    "           validation_data=(val_inps, answers_test))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 1.8966 - acc: 0.1656 - val_loss: 1.8038 - val_acc: 0.1840\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.8115 - acc: 0.1713 - val_loss: 1.8247 - val_acc: 0.1600\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.8077 - acc: 0.1587 - val_loss: 1.8085 - val_acc: 0.1650\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 1.8042 - acc: 0.1660 - val_loss: 1.8062 - val_acc: 0.1600\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.8008 - acc: 0.1735 - val_loss: 1.7942 - val_acc: 0.1750\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.7971 - acc: 0.1712 - val_loss: 1.7951 - val_acc: 0.1870\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.7972 - acc: 0.1666 - val_loss: 1.7923 - val_acc: 0.1740\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.7992 - acc: 0.1692 - val_loss: 1.7979 - val_acc: 0.1650\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 1.7976 - acc: 0.1741 - val_loss: 1.7930 - val_acc: 0.1670\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.8014 - acc: 0.1835 - val_loss: 1.8008 - val_acc: 0.1670\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.8289 - acc: 0.2139 - val_loss: 1.8122 - val_acc: 0.1940\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.8225 - acc: 0.2165 - val_loss: 1.8080 - val_acc: 0.1670\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 45s 5ms/step - loss: 1.8006 - acc: 0.1722 - val_loss: 1.8003 - val_acc: 0.1580\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.7964 - acc: 0.1718 - val_loss: 1.7927 - val_acc: 0.1870\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.7934 - acc: 0.1765 - val_loss: 1.7936 - val_acc: 0.1870\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.7949 - acc: 0.1747 - val_loss: 1.7940 - val_acc: 0.1870\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 1.7911 - acc: 0.1920 - val_loss: 1.7971 - val_acc: 0.2120\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.7745 - acc: 0.3055 - val_loss: 1.6653 - val_acc: 0.3580\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 1.6942 - acc: 0.3421 - val_loss: 1.7161 - val_acc: 0.3980\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.6642 - acc: 0.4371 - val_loss: 1.5892 - val_acc: 0.4860\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.6004 - acc: 0.4784 - val_loss: 1.6601 - val_acc: 0.4050\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.5633 - acc: 0.4919 - val_loss: 1.4962 - val_acc: 0.5330\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 1.4481 - acc: 0.5428 - val_loss: 1.1539 - val_acc: 0.6460\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 1.1918 - acc: 0.6700 - val_loss: 1.0832 - val_acc: 0.7080\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.1424 - acc: 0.6898 - val_loss: 1.0109 - val_acc: 0.7230\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 1.0638 - acc: 0.6975 - val_loss: 1.0609 - val_acc: 0.7060\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 1.0301 - acc: 0.7082 - val_loss: 0.8950 - val_acc: 0.7390\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 50s 5ms/step - loss: 1.0124 - acc: 0.7060 - val_loss: 0.9066 - val_acc: 0.7670\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 0.9788 - acc: 0.7137 - val_loss: 0.8780 - val_acc: 0.7520\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.9887 - acc: 0.7073 - val_loss: 0.8901 - val_acc: 0.7310\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 0.9721 - acc: 0.7135 - val_loss: 0.8941 - val_acc: 0.7400\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.9929 - acc: 0.7175 - val_loss: 0.8762 - val_acc: 0.7460\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 1.0184 - acc: 0.7135 - val_loss: 0.8811 - val_acc: 0.7460\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.9469 - acc: 0.7305 - val_loss: 0.8687 - val_acc: 0.7600\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 51s 5ms/step - loss: 0.9589 - acc: 0.7230 - val_loss: 0.9316 - val_acc: 0.7380\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 0.9618 - acc: 0.7213 - val_loss: 0.9007 - val_acc: 0.7450\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.9658 - acc: 0.7224 - val_loss: 0.8691 - val_acc: 0.7640\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.9635 - acc: 0.7203 - val_loss: 0.8243 - val_acc: 0.7550\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 49s 5ms/step - loss: 0.9703 - acc: 0.7234 - val_loss: 0.9144 - val_acc: 0.7490\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.9473 - acc: 0.7353 - val_loss: 0.8948 - val_acc: 0.7550\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9498 - acc: 0.7307 - val_loss: 0.8887 - val_acc: 0.7200\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 0.9588 - acc: 0.7276 - val_loss: 0.8285 - val_acc: 0.7690\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 51s 5ms/step - loss: 1.0051 - acc: 0.7179 - val_loss: 0.9812 - val_acc: 0.7550\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 1.0083 - acc: 0.7273 - val_loss: 0.8858 - val_acc: 0.7500\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 55s 6ms/step - loss: 0.9431 - acc: 0.7400 - val_loss: 0.9064 - val_acc: 0.7410\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9324 - acc: 0.7364 - val_loss: 0.8422 - val_acc: 0.7750\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 55s 5ms/step - loss: 0.9456 - acc: 0.7325 - val_loss: 0.8459 - val_acc: 0.7710\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9504 - acc: 0.7321 - val_loss: 0.8627 - val_acc: 0.7670\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 52s 5ms/step - loss: 0.9606 - acc: 0.7348 - val_loss: 0.9628 - val_acc: 0.7450\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 0.9553 - acc: 0.7376 - val_loss: 0.8060 - val_acc: 0.7800\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 58s 6ms/step - loss: 0.9445 - acc: 0.7324 - val_loss: 0.8013 - val_acc: 0.7720\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.9568 - acc: 0.7347 - val_loss: 0.9508 - val_acc: 0.7460\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 58s 6ms/step - loss: 0.9457 - acc: 0.7413 - val_loss: 0.8335 - val_acc: 0.7770\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.9506 - acc: 0.7368 - val_loss: 0.8943 - val_acc: 0.7480\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 0.9427 - acc: 0.7322 - val_loss: 0.8742 - val_acc: 0.7640\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 0.9221 - acc: 0.7437 - val_loss: 0.8400 - val_acc: 0.7710\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9295 - acc: 0.7353 - val_loss: 0.8485 - val_acc: 0.7780\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.9402 - acc: 0.7412 - val_loss: 0.8700 - val_acc: 0.7580\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 60s 6ms/step - loss: 0.9178 - acc: 0.7426 - val_loss: 0.9250 - val_acc: 0.7070\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 0.9934 - acc: 0.7290 - val_loss: 0.8906 - val_acc: 0.7670\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.9904 - acc: 0.7284 - val_loss: 0.8800 - val_acc: 0.7620\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 46s 5ms/step - loss: 0.9564 - acc: 0.7297 - val_loss: 0.7907 - val_acc: 0.7860\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.9377 - acc: 0.7340 - val_loss: 0.8371 - val_acc: 0.7710\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 48s 5ms/step - loss: 0.9396 - acc: 0.7352 - val_loss: 0.9101 - val_acc: 0.7460\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 0.9341 - acc: 0.7391 - val_loss: 0.8443 - val_acc: 0.7730\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 56s 6ms/step - loss: 0.9391 - acc: 0.7423 - val_loss: 0.8584 - val_acc: 0.7500\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 55s 6ms/step - loss: 0.9260 - acc: 0.7441 - val_loss: 0.8972 - val_acc: 0.7420\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 55s 6ms/step - loss: 1.0059 - acc: 0.7285 - val_loss: 0.9419 - val_acc: 0.7630\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 53s 5ms/step - loss: 0.9720 - acc: 0.7326 - val_loss: 0.9038 - val_acc: 0.7350\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 59s 6ms/step - loss: 0.9434 - acc: 0.7361 - val_loss: 0.8700 - val_acc: 0.7420\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9213 - acc: 0.7398 - val_loss: 0.8769 - val_acc: 0.7420\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 55s 5ms/step - loss: 0.9323 - acc: 0.7422 - val_loss: 0.7835 - val_acc: 0.7850\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 55s 5ms/step - loss: 0.9285 - acc: 0.7404 - val_loss: 0.8559 - val_acc: 0.7540\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 59s 6ms/step - loss: 0.9498 - acc: 0.7351 - val_loss: 0.9464 - val_acc: 0.7190\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9611 - acc: 0.7270 - val_loss: 0.8341 - val_acc: 0.7720\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 55s 5ms/step - loss: 0.9536 - acc: 0.7331 - val_loss: 1.0085 - val_acc: 0.7160\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 47s 5ms/step - loss: 0.9547 - acc: 0.7364 - val_loss: 0.7996 - val_acc: 0.7660\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9465 - acc: 0.7336 - val_loss: 0.9205 - val_acc: 0.7630\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 52s 5ms/step - loss: 0.9719 - acc: 0.7360 - val_loss: 0.8438 - val_acc: 0.7610\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 54s 5ms/step - loss: 0.9414 - acc: 0.7330 - val_loss: 0.8865 - val_acc: 0.7530\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 57s 6ms/step - loss: 0.9170 - acc: 0.7410 - val_loss: 0.8534 - val_acc: 0.7710\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 52s 5ms/step - loss: 0.9617 - acc: 0.7359 - val_loss: 0.9040 - val_acc: 0.7580\n",
      "Epoch 83/100\n",
      " 3744/10000 [==========>...................] - ETA: 34s - loss: 0.9642 - acc: 0.7444"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a2858f5dd57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m hist=answer.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n\u001b[1;32m---> 39\u001b[1;33m            validation_data=(val_inps, answers_test))\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "emb_dim = 40\n",
    "def emb_sent_bow(inp):\n",
    "    emb_op = layers.TimeDistributed(Embedding(vocab_size, emb_dim, embeddings_regularizer=regularizers.l2(0.002)))\n",
    "    emb = emb_op(inp)\n",
    "    emb = layers.Dropout(0.1)(emb)\n",
    "    emb = layers.Lambda(lambda x: K.sum(x, 2))(emb)\n",
    "#     return Elemwise(0, False)(emb), emb_op\n",
    "    return emb, emb_op\n",
    "inp_story = layers.Input((story_maxsents, story_maxlen))\n",
    "inp_q = layers.Input((query_maxlen,))\n",
    "emb_story, emb_story_op = emb_sent_bow(inp_story)\n",
    "emb_q = emb_story_op.layer(inp_q)\n",
    "emb_q = layers.Lambda(lambda x: K.sum(x, 1))(emb_q)\n",
    "h = layers.Dense(emb_dim, kernel_regularizer=regularizers.l2(0.0000))\n",
    "def one_hop(u, A):\n",
    "    C, _ = emb_sent_bow(inp_story)\n",
    "    x = layers.Reshape((1, emb_dim))(u)\n",
    "    x = layers.Dot(axes=2)([A, x])\n",
    "    x = layers.Reshape((story_maxsents,))(x)\n",
    "    x = layers.Activation('softmax')(x)\n",
    "    match = layers.Reshape((story_maxsents,1))(x)\n",
    "\n",
    "    x = layers.Dot(axes=1)([match, C])\n",
    "    x = layers.Reshape((emb_dim,))(x)\n",
    "    x = h(x)\n",
    "    #x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Add()([x, emb_q])\n",
    "    return x, C\n",
    "response, emb_story = one_hop(emb_q, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)\n",
    "response, emb_story = one_hop(response, emb_story)\n",
    "res = layers.Dense(vocab_size, activation='softmax')(response)\n",
    "answer = Model([inp_story, inp_q], res)\n",
    "answer.compile(optimizer='adam', loss='sparse_categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "K.set_value(answer.optimizer.lr, 5e-3)\n",
    "hist=answer.fit(inps, answers_train, nb_epoch=100, batch_size=32,\n",
    "           validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 39s 4ms/step - loss: 1.8488 - acc: 0.1860 - val_loss: 1.7652 - val_acc: 0.2680\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 1.7292 - acc: 0.2999 - val_loss: 1.7123 - val_acc: 0.2940\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 1.7836 - acc: 0.2048 - val_loss: 1.8048 - val_acc: 0.1680\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 1.7818 - acc: 0.2149 - val_loss: 1.7957 - val_acc: 0.1860\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 1.8013 - acc: 0.1663 - val_loss: 1.7930 - val_acc: 0.1770\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 1.7665 - acc: 0.2362 - val_loss: 1.7708 - val_acc: 0.2900\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 1.7152 - acc: 0.3032 - val_loss: 1.6816 - val_acc: 0.2860\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 1.3912 - acc: 0.5098 - val_loss: 1.2363 - val_acc: 0.6430\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 1.1056 - acc: 0.6843 - val_loss: 1.1419 - val_acc: 0.6700\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 1.0722 - acc: 0.6999 - val_loss: 1.1064 - val_acc: 0.6840\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.9987 - acc: 0.7293 - val_loss: 1.0460 - val_acc: 0.7170\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 29s 3ms/step - loss: 0.9988 - acc: 0.7300 - val_loss: 1.1119 - val_acc: 0.7030\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 1.0682 - acc: 0.7049 - val_loss: 1.2186 - val_acc: 0.6540\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 34s 3ms/step - loss: 1.0179 - acc: 0.7250 - val_loss: 1.0229 - val_acc: 0.7310\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.9992 - acc: 0.7346 - val_loss: 1.0725 - val_acc: 0.7270\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.9559 - acc: 0.7505 - val_loss: 0.9771 - val_acc: 0.7530\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 30s 3ms/step - loss: 0.9670 - acc: 0.7444 - val_loss: 1.0821 - val_acc: 0.7110\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 32s 3ms/step - loss: 0.9733 - acc: 0.7447 - val_loss: 1.0918 - val_acc: 0.7150\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 31s 3ms/step - loss: 0.9631 - acc: 0.7465 - val_loss: 1.0623 - val_acc: 0.7220\n",
      "Epoch 20/100\n",
      " 2112/10000 [=====>........................] - ETA: 24s - loss: 0.9584 - acc: 0.7486"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-3417f08db431>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     49\u001b[0m babi2.fit(inps, answers_train, batch_size=32, epochs=100,\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m           validation_data=(val_inps, answers_test))\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2719\u001b[0m                     \u001b[1;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[1;32m-> 2721\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2693\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2694\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1325\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\nlandy\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_hidden = 64\n",
    "max_num_memories = story_maxsents\n",
    "max_memory_len = story_maxlen\n",
    "max_ques_len = query_maxlen\n",
    "\n",
    "mem_input = layers.Input(shape=(max_num_memories, max_memory_len))\n",
    "query_input = layers.Input(shape=(max_ques_len,))\n",
    "A1 = Embedding(vocab_size,output_dim=n_hidden)\n",
    "m_i = layers.TimeDistributed(A1)(mem_input)\n",
    "m_i = layers.Lambda(lambda x: K.sum(x, 2))(m_i)\n",
    "B = A1 #as specified\n",
    "u1 = B(query_input)\n",
    "u1 = (layers.Lambda(lambda x: K.sum(x, 1)))(u1)\n",
    "u1 = layers.Reshape((1, n_hidden))(u1)\n",
    "C1 = layers.Embedding(vocab_size,output_dim=n_hidden)\n",
    "c_i_1 = layers.TimeDistributed(C1)(mem_input)\n",
    "c_i_1 = layers.Lambda(lambda x: K.sum(x, 2))(c_i_1)\n",
    "p1 = layers.dot([m_i, u1], axes=2)\n",
    "p1 = layers.Reshape((max_num_memories,))(p1)\n",
    "p1 = layers.Activation(activation='softmax')(p1)\n",
    "p1 = layers.Reshape((max_num_memories,1))(p1)\n",
    "o1 = layers.dot([c_i_1, p1], axes=1)\n",
    "o1 = layers.Reshape(target_shape=(n_hidden,))(o1)\n",
    "u1 = layers.Reshape((n_hidden,))(u1)\n",
    "u2 = layers.add([o1, u1])\n",
    "\n",
    "A2 = C1 #A(k + 1) = C(k)\n",
    "m_i = layers.TimeDistributed(A2)(mem_input)\n",
    "m_i = layers.Lambda(lambda x: K.sum(x, 2))(m_i)\n",
    "C2 = layers.Embedding(vocab_size,output_dim=n_hidden)\n",
    "c_i_2 = layers.TimeDistributed(C2)(mem_input)\n",
    "c_i_2 = layers.Lambda(lambda x: K.sum(x, 2))(c_i_2)\n",
    "u2 = layers.Reshape((1, n_hidden))(u2)\n",
    "p2 = layers.dot([m_i, u2], axes=2)\n",
    "p2 = layers.Reshape((max_num_memories,))(p2)\n",
    "p2 = layers.Activation(activation='softmax')(p2)\n",
    "p2 = layers.Reshape((max_num_memories,1))(p2)\n",
    "o2 = layers.dot([c_i_2, p2], axes=1)\n",
    "o2 = layers.Reshape(target_shape=(n_hidden,))(o2)\n",
    "u2 = layers.Reshape((n_hidden,))(u2)\n",
    "u1 = layers.Reshape((n_hidden,))(u1)\n",
    "#u3 = add([o2, u1]) #u(k + 1) = o(k) + u(k)\n",
    "#This is a hack, I was not able to get good results with u3 = u2 + o2\n",
    "u3 = layers.add([o2, u1]) #u(k + 1) = o(k) + u(k)\n",
    "answer = layers.Dense(vocab_size, activation='softmax')(u3)\n",
    "babi2 = Model([mem_input, query_input], answer)\n",
    "babi2.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "K.set_value(babi2.optimizer.lr, 5e-3)\n",
    "babi2.fit(inps, answers_train, batch_size=32, epochs=100,\n",
    "\n",
    "          validation_data=(val_inps, answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
